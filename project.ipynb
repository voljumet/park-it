{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Park a lot\n",
    "\n",
    "This notebook is put together by the following parts:  \n",
    "1. A function to segment video frames to locate cars, which will be used to check if the car is going in or out of the parking lot or garage.  \n",
    "2. A function to read license plate on the segmented frames that will be converted to a string and stored in the \n",
    "3. A csv file containing the parking times of the license plates and the size of the car.\n",
    "4. An additional csv file containing the cars currently in the parking that will be checked against when a license plate apears on the camera.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "# to run the code, the following are required, and should be installed in a new environment:\n",
    "\n",
    "# create new environment\n",
    "%conda create -n \"park-3.9\" python=3.9 ipython\n",
    "# activate environment\n",
    "%conda activate park-3.9\n",
    "# install package\n",
    "%conda install numpy\n",
    "# install requirements.txt\n",
    "%pip install -r requirements.txt --verbose\n",
    "# install ipykernel\n",
    "%conda install -n park-3.9 ipykernel --update-deps --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# limit the number of cpus used by high performance libraries\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"4\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"4\"\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import csv\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it\n",
      "/Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it\n"
     ]
    }
   ],
   "source": [
    "# import more libraries ++\n",
    "ROOT = Path(os.getcwd()).resolve()  # yolov5 strongsort root directory\n",
    "WEIGHTS = ROOT / 'weights'\n",
    "print(os.getcwd())\n",
    "\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "if str(ROOT / 'yolov5') not in sys.path:\n",
    "    sys.path.append(str(ROOT / 'yolov5'))  # add yolov5 ROOT to PATH\n",
    "if str(ROOT / 'trackers' / 'strong_sort') not in sys.path:\n",
    "    sys.path.append(str(ROOT / 'trackers' / 'strong_sort'))  # add strong_sort ROOT to PATH\n",
    "if str(ROOT / 'trackers' / 'strong_sort' / 'sort') not in sys.path:\n",
    "    sys.path.append(str(ROOT / 'trackers' / 'strong_sort' / 'sort'))  # add strong_sort ROOT to PATH\n",
    "\n",
    "import logging\n",
    "from yolov5.models.common import DetectMultiBackend\n",
    "from yolov5.utils.dataloaders import VID_FORMATS, LoadImages, LoadStreams\n",
    "from yolov5.utils.general import (LOGGER, check_img_size, non_max_suppression, scale_boxes, check_requirements, cv2,\n",
    "                                  check_imshow, xyxy2xywh, increment_path, strip_optimizer, colorstr, print_args, check_file)\n",
    "from yolov5.utils.torch_utils import select_device, time_sync\n",
    "from yolov5.utils.plots import Annotator, colors, save_one_box\n",
    "from trackers.multi_tracker_zoo import create_tracker\n",
    "\n",
    "# set working directory to this file\n",
    "os.chdir(ROOT)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track and sort\n",
    "@torch.no_grad()\n",
    "def run(threshold_1=1,\n",
    "        threshold_2=1,\n",
    "        smallest_boundingbox_width=1,\n",
    "        smallest_boundingbox_heigth=1,\n",
    "        source='0',\n",
    "        yolo_weights=WEIGHTS / 'yolov5m.pt',  # model.pt path(s),\n",
    "        reid_weights=WEIGHTS / 'osnet_x0_25_msmt17.pt',  # model.pt path,\n",
    "        tracking_method='strongsort',\n",
    "        imgsz=(640, 640),  # inference size (height, width)\n",
    "        conf_thres=0.25,  # confidence threshold\n",
    "        iou_thres=0.45,  # NMS IOU threshold\n",
    "        max_det=1000,  # maximum detections per image\n",
    "        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "        show_vid=False,  # show results\n",
    "        save_txt=False,  # save results to *.txt\n",
    "        save_conf=False,  # save confidences in --save-txt labels\n",
    "        save_crop=False,  # save cropped prediction boxes\n",
    "        save_vid=False,  # save confidences in --save-txt labels\n",
    "        nosave=False,  # do not save images/videos\n",
    "        classes=None,  # filter by class: --class 0, or --class 0 2 3\n",
    "        agnostic_nms=False,  # class-agnostic NMS\n",
    "        augment=False,  # augmented inference\n",
    "        visualize=False,  # visualize features\n",
    "        update=False,  # update all models\n",
    "        project=ROOT / 'runs/track',  # save results to project/name\n",
    "        name='exp',  # save results to project/name\n",
    "        exist_ok=False,  # existing project/name ok, do not increment\n",
    "        line_thickness=2,  # bounding box thickness (pixels)\n",
    "        hide_labels=False,  # hide labels\n",
    "        hide_conf=False,  # hide confidences\n",
    "        hide_class=False,  # hide IDs\n",
    "        half=False,  # use FP16 half-precision inference\n",
    "        dnn=False,  # use OpenCV DNN for ONNX inference\n",
    "        vid_stride=1,  # video frame-rate stride\n",
    "):\n",
    "\n",
    "    source = str(source)\n",
    "    save_img = not nosave and not source.endswith('.txt')  # save inference images\n",
    "    is_file = Path(source).suffix[1:] in (VID_FORMATS)\n",
    "    is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
    "    webcam = source.isnumeric() or source.endswith('.txt') or (is_url and not is_file)\n",
    "    if is_url and is_file:\n",
    "        source = check_file(source)  # download\n",
    "\n",
    "    # Directories\n",
    "    if not isinstance(yolo_weights, list):  # single yolo model\n",
    "        exp_name = yolo_weights.stem\n",
    "    elif type(yolo_weights) is list and len(yolo_weights) == 1:  # single models after --yolo_weights\n",
    "        exp_name = Path(yolo_weights[0]).stem\n",
    "    else:  # multiple models after --yolo_weights\n",
    "        exp_name = 'ensemble'\n",
    "    exp_name = name if name else exp_name + \"_\" + reid_weights.stem\n",
    "    save_dir = increment_path(Path(project) / exp_name, exist_ok=exist_ok)  # increment run\n",
    "    (save_dir / 'tracks' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "    # Load model\n",
    "    device = select_device(device)\n",
    "    model = DetectMultiBackend(yolo_weights, device=device, dnn=dnn, data=None, fp16=half)\n",
    "    stride, names, pt = model.stride, model.names, model.pt\n",
    "    imgsz = check_img_size(imgsz, s=stride)  # check image size\n",
    "\n",
    "    # Dataloader\n",
    "    if webcam:\n",
    "        show_vid = check_imshow()\n",
    "        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)\n",
    "        nr_sources = len(dataset)\n",
    "    else:\n",
    "        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)\n",
    "        nr_sources = 1\n",
    "    vid_path, vid_writer, txt_path = [None] * nr_sources, [None] * nr_sources, [None] * nr_sources\n",
    "\n",
    "    # Create as many strong sort instances as there are video sources\n",
    "    tracker_list = []\n",
    "    for i in range(nr_sources):\n",
    "        tracker = create_tracker(tracking_method, reid_weights, device, half)\n",
    "        tracker_list.append(tracker, )\n",
    "        if hasattr(tracker_list[i], 'model'):\n",
    "            if hasattr(tracker_list[i].model, 'warmup'):\n",
    "                tracker_list[i].model.warmup()\n",
    "    outputs = [None] * nr_sources\n",
    "    print(outputs)\n",
    "\n",
    "    # Run tracking\n",
    "    #model.warmup(imgsz=(1 if pt else nr_sources, 3, *imgsz))  # warmup\n",
    "    dt, seen = [0.0, 0.0, 0.0, 0.0], 0\n",
    "    curr_frames, prev_frames = [None] * nr_sources, [None] * nr_sources\n",
    "    temp_array = \"\"\n",
    "    for frame_idx, (path, im, im0s, vid_cap, s) in enumerate(dataset):\n",
    "        if frame_idx % 5 != 0:\n",
    "            continue\n",
    "        t1 = time_sync()\n",
    "        im = torch.from_numpy(im).to(device)\n",
    "        im = im.half() if half else im.float()  # uint8 to fp16/32\n",
    "        im /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]  # expand for batch dim\n",
    "        t2 = time_sync()\n",
    "        dt[0] += t2 - t1\n",
    "\n",
    "        # Inference\n",
    "        visualize = increment_path(save_dir / Path(path[0]).stem, mkdir=True) if visualize else False\n",
    "        pred = model(im, augment=augment, visualize=visualize)\n",
    "        t3 = time_sync()\n",
    "        dt[1] += t3 - t2\n",
    "\n",
    "        # Apply NMS\n",
    "        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
    "        dt[2] += time_sync() - t3\n",
    "\n",
    "        \n",
    "        # Process detections\n",
    "        for i, det in enumerate(pred):  # detections per image\n",
    "            seen += 1\n",
    "            if webcam:  # nr_sources >= 1\n",
    "                p, im0, _ = path[i], im0s[i].copy(), dataset.count\n",
    "                p = Path(p)  # to Path\n",
    "                s += f'{i}: '\n",
    "                txt_file_name = p.name\n",
    "                save_path = str(save_dir / p.name)  # im.jpg, vid.mp4, ...\n",
    "            else:\n",
    "                p, im0, _ = path, im0s.copy(), getattr(dataset, 'frame', 0)\n",
    "                p = Path(p)  # to Path\n",
    "                # video file\n",
    "                if source.endswith(VID_FORMATS):\n",
    "                    txt_file_name = p.stem\n",
    "                    save_path = str(save_dir / p.name)  # im.jpg, vid.mp4, ...\n",
    "                # folder with imgs\n",
    "                else:\n",
    "                    txt_file_name = p.parent.name  # get folder name containing current img\n",
    "                    save_path = str(save_dir / p.parent.name)  # im.jpg, vid.mp4, ...\n",
    "            curr_frames[i] = im0\n",
    "\n",
    "            txt_path = str(save_dir / 'tracks' / txt_file_name)  # im.txt\n",
    "            s += '%gx%g ' % im.shape[2:]  # print string\n",
    "            imc = im0.copy() if save_crop else im0  # for save_crop\n",
    "\n",
    "            annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "            \n",
    "            if hasattr(tracker_list[i], 'tracker') and hasattr(tracker_list[i].tracker, 'camera_update'):\n",
    "                if prev_frames[i] is not None and curr_frames[i] is not None:  # camera motion compensation\n",
    "                    tracker_list[i].tracker.camera_update(prev_frames[i], curr_frames[i])\n",
    "\n",
    "            if det is not None and len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()  # xyxy\n",
    "\n",
    "                # Print results\n",
    "                for c in det[:, -1].unique():\n",
    "                    n = (det[:, -1] == c).sum()  # detections per class\n",
    "                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "\n",
    "                # pass detections to strongsort\n",
    "                t4 = time_sync()\n",
    "                outputs[i] = tracker_list[i].update(det.cpu(), im0)\n",
    "                t5 = time_sync()\n",
    "                dt[3] += t5 - t4\n",
    "\n",
    "                # draw boxes for visualization\n",
    "                if len(outputs[i]) > 0:\n",
    "                    for j, (output, conf) in enumerate(zip(outputs[i], det[:, 4])):\n",
    "\n",
    "\n",
    "                    # ------------------------------------------------------ SAVE TO FILE  ----------------------------------------------------------\n",
    "                        bbox_top = output[1]\n",
    "                        bbox_w = output[2] - output[0]\n",
    "                        bbox_h = output[3] - output[1]\n",
    "\n",
    "                        cv2.line(im0, (0, threshold_1), (im0.shape[1], threshold_1), (255, 0, 0), 2) # Blue\n",
    "                        cv2.line(im0, (0, threshold_2), (im0.shape[1], threshold_2), (255, 0, 0), 2) # Blue\n",
    "\n",
    "                        if (bbox_top+bbox_h < threshold_1) and (bbox_top+bbox_h > threshold_2) and(bbox_w > smallest_boundingbox_width) and (bbox_h > smallest_boundingbox_heigth):\n",
    "                            cv2.imwrite(str(save_dir)+\"/frame id_\"+str(frame_idx+1)+\".jpg\", im0)\n",
    "\n",
    "\n",
    "                            bboxes = output[0:4]\n",
    "                            id = output[4]\n",
    "                            cls = output[5]\n",
    "                            if save_txt:\n",
    "                                # to MOT format\n",
    "                                bbox_left = output[0]\n",
    "                                # append to string\n",
    "\n",
    "                                # add info to array\n",
    "                                if frame_idx % 100 != 0:\n",
    "                                    temp_array += f'{frame_idx + 1},{id},{bbox_left},{bbox_top},{bbox_w},{bbox_h},{time.time()}\\n'\n",
    "                                else:\n",
    "                                    # Write MOT compliant results to file\n",
    "                                    with open(txt_path + '.csv', 'a') as f:\n",
    "                                        f.write(temp_array)\n",
    "                                        f.close()\n",
    "                                        temp_array = \"\"\n",
    "\n",
    "                            if save_vid or save_crop or show_vid:  # Add bbox to image\n",
    "                                c = int(cls)  # integer class\n",
    "                                id = int(id)  # integer id\n",
    "                                label = None if hide_labels else (f'{id} {names[c]}' if hide_conf else \\\n",
    "                                    (f'{id} {conf:.2f}' if hide_class else f'{id} {names[c]} {conf:.2f}'))\n",
    "                                annotator.box_label(bboxes, label, color=colors(c, True))\n",
    "                                if save_crop:\n",
    "                                    txt_file_name = txt_file_name if (isinstance(path, list) and len(path) > 1) else ''\n",
    "                                    save_one_box(bboxes, imc, file=save_dir / 'crops' / txt_file_name / names[c] / f'{id}' / f'{p.stem}.jpg', BGR=True)\n",
    "\n",
    "                LOGGER.info(f'{s}Done. yolo:({t3 - t2:.3f}s), {tracking_method}:({t5 - t4:.3f}s)')\n",
    "\n",
    "            else:\n",
    "                #strongsort_list[i].increment_ages()\n",
    "                LOGGER.info('No detections')          \n",
    "\n",
    "            # Stream results\n",
    "            im0 = annotator.result()\n",
    "            if show_vid:\n",
    "                cv2.imshow(str(p), im0)\n",
    "                cv2.waitKey(1)  # 1 millisecond\n",
    "\n",
    "            # Save results (image with detections)\n",
    "            if save_vid:\n",
    "                if vid_path[i] != save_path:  # new video\n",
    "                    vid_path[i] = save_path\n",
    "                    if isinstance(vid_writer[i], cv2.VideoWriter):\n",
    "                        vid_writer[i].release()  # release previous video writer\n",
    "                    if vid_cap:  # video\n",
    "                        fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "                        w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                        h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                    else:  # stream\n",
    "                        fps, w, h = 30, im0.shape[1], im0.shape[0]\n",
    "                    save_path = str(Path(save_path).with_suffix('.mp4'))  # force *.mp4 suffix on results videos\n",
    "                    vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "                vid_writer[i].write(im0)\n",
    "\n",
    "            prev_frames[i] = curr_frames[i]\n",
    "\n",
    "    # Print results\n",
    "    t = tuple(x / seen * 1E3 for x in dt)  # speeds per image\n",
    "    LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS, %.1fms {tracking_method} update per image at shape {(1, 3, *imgsz)}' % t)\n",
    "    if save_txt or save_vid:\n",
    "        s = f\"\\n{len(list(save_dir.glob('tracks/*.txt')))} tracks saved to {save_dir / 'tracks'}\" if save_txt else ''\n",
    "        LOGGER.info(f\"Results saved to {colorstr('bold', save_dir)}{s}\")\n",
    "    if update:\n",
    "        strip_optimizer(yolo_weights)  # update model (to fix SourceChangeWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set arguments for the track and sort function\n",
    "def parse_opt(video_path):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--yolo-weights', nargs='+', type=Path, default=WEIGHTS / 'yolov5n.pt', help='model.pt path(s)')\n",
    "    parser.add_argument('--reid-weights', type=Path, default=WEIGHTS / 'osnet_x0_25_msmt17.pt')\n",
    "    parser.add_argument('--tracking-method', type=str, default='strongsort', help='strongsort, ocsort, bytetrack')\n",
    "    parser.add_argument('--source', type=str, default='0', help='file/dir/URL/glob, 0 for webcam')  \n",
    "    parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=[640], help='inference size h,w')\n",
    "    parser.add_argument('--conf-thres', type=float, default=0.5, help='confidence threshold')\n",
    "    parser.add_argument('--iou-thres', type=float, default=0.5, help='NMS IoU threshold')\n",
    "    parser.add_argument('--max-det', type=int, default=1000, help='maximum detections per image')\n",
    "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "    parser.add_argument('--show-vid', action='store_true', help='display tracking video results')\n",
    "    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')\n",
    "    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')\n",
    "    parser.add_argument('--save-crop', action='store_true', help='save cropped prediction boxes')\n",
    "    parser.add_argument('--save-vid', action='store_true', help='save video tracking results')\n",
    "    parser.add_argument('--nosave', action='store_true', help='do not save images/videos')\n",
    "    # class 0 is person, 1 is bycicle, 2 is car... 79 is oven\n",
    "    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --classes 0, or --classes 0 2 3')\n",
    "    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')\n",
    "    parser.add_argument('--augment', action='store_true', help='augmented inference')\n",
    "    parser.add_argument('--visualize', action='store_true', help='visualize features')\n",
    "    parser.add_argument('--update', action='store_true', help='update all models')\n",
    "    parser.add_argument('--project', default=ROOT / 'runs/track', help='save results to project/name')\n",
    "    parser.add_argument('--name', default='exp', help='save results to project/name')\n",
    "    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
    "    parser.add_argument('--line-thickness', default=2, type=int, help='bounding box thickness (pixels)')\n",
    "    parser.add_argument('--hide-labels', default=False, action='store_true', help='hide labels')\n",
    "    parser.add_argument('--hide-conf', default=False, action='store_true', help='hide confidences')\n",
    "    parser.add_argument('--hide-class', default=False, action='store_true', help='hide IDs')\n",
    "    parser.add_argument('--half', action='store_true', help='use FP16 half-precision inference')\n",
    "    parser.add_argument('--dnn', action='store_true', help='use OpenCV DNN for ONNX inference')\n",
    "    parser.add_argument('--vid-stride', type=int, default=1, help='video frame-rate stride')\n",
    "\n",
    "    opt = parser.parse_args(['--source', video_path,\n",
    "                             '--classes', '2',\n",
    "                             '--save-txt'\n",
    "                             ,'--show-vid'\n",
    "                             ])\n",
    "\n",
    "    # source\n",
    "    # opt.source = \"../park-a-lot/film.mp4\"\n",
    "\n",
    "    # detect only car class\n",
    "    # opt.classes = 2\n",
    "    \n",
    "    # save text file\n",
    "    # opt.save_txt = True\n",
    "    # print working directory\n",
    "    # print(os.getcwd())\n",
    "\n",
    "    opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1  # expand\n",
    "    print_args(vars(opt))\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1m2019945111: \u001b[0myolo_weights=/Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/weights/yolov5n.pt, reid_weights=/Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/weights/osnet_x0_25_msmt17.pt, tracking_method=strongsort, source=IMG_0346.mp4, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.5, max_det=1000, device=, show_vid=True, save_txt=True, save_conf=False, save_crop=False, save_vid=False, nosave=False, classes=[2], agnostic_nms=False, augment=False, visualize=False, update=False, project=/Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/runs/track, name=exp, exist_ok=False, line_thickness=2, hide_labels=False, hide_conf=False, hide_class=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 🚀 2022-12-2 Python-3.9.15 torch-1.13.0 CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n.pt to /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/weights/yolov5n.pt...\n",
      "100%|██████████| 3.87M/3.87M [00:00<00:00, 13.8MB/s]\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
      "No detections\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded pretrained weights from \"/Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/weights/osnet_x0_25_msmt17.pt\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
      "[None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "video 1/1 (186/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.037s), strongsort:(0.015s)\n",
      "video 1/1 (191/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.038s), strongsort:(0.015s)\n",
      "video 1/1 (196/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.036s), strongsort:(0.016s)\n",
      "video 1/1 (201/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.040s), strongsort:(0.018s)\n",
      "video 1/1 (206/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.034s), strongsort:(0.017s)\n",
      "video 1/1 (211/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.019s)\n",
      "video 1/1 (216/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.020s)\n",
      "video 1/1 (221/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.040s), strongsort:(0.021s)\n",
      "video 1/1 (226/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.037s), strongsort:(0.022s)\n",
      "video 1/1 (231/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.037s), strongsort:(0.022s)\n",
      "video 1/1 (236/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.024s)\n",
      "video 1/1 (241/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.037s), strongsort:(0.023s)\n",
      "video 1/1 (246/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.040s), strongsort:(0.023s)\n",
      "video 1/1 (251/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.023s)\n",
      "video 1/1 (256/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.036s), strongsort:(0.023s)\n",
      "video 1/1 (261/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.033s), strongsort:(0.023s)\n",
      "video 1/1 (266/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.034s), strongsort:(0.023s)\n",
      "video 1/1 (271/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.034s), strongsort:(0.021s)\n",
      "video 1/1 (276/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.039s), strongsort:(0.023s)\n",
      "video 1/1 (281/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.036s), strongsort:(0.022s)\n",
      "video 1/1 (286/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.023s)\n",
      "video 1/1 (291/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.020s)\n",
      "video 1/1 (296/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.036s), strongsort:(0.025s)\n",
      "video 1/1 (301/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.026s)\n",
      "video 1/1 (306/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.037s), strongsort:(0.024s)\n",
      "video 1/1 (311/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.040s), strongsort:(0.037s)\n",
      "video 1/1 (316/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.036s), strongsort:(0.028s)\n",
      "video 1/1 (321/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.041s), strongsort:(0.030s)\n",
      "video 1/1 (326/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.039s)\n",
      "video 1/1 (331/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.034s), strongsort:(0.037s)\n",
      "video 1/1 (336/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.044s)\n",
      "video 1/1 (341/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.039s)\n",
      "video 1/1 (346/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.034s), strongsort:(0.040s)\n",
      "video 1/1 (351/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.060s), strongsort:(0.042s)\n",
      "video 1/1 (356/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.044s), strongsort:(0.046s)\n",
      "video 1/1 (361/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.044s), strongsort:(0.050s)\n",
      "No detections\n",
      "video 1/1 (371/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.060s), strongsort:(0.037s)\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "video 1/1 (401/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.037s), strongsort:(0.031s)\n",
      "No detections\n",
      "video 1/1 (411/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.040s), strongsort:(0.031s)\n",
      "video 1/1 (416/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.043s), strongsort:(0.027s)\n",
      "video 1/1 (421/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.049s), strongsort:(0.024s)\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "video 1/1 (986/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.038s), strongsort:(0.028s)\n",
      "video 1/1 (991/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.039s), strongsort:(0.030s)\n",
      "video 1/1 (996/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.037s), strongsort:(0.030s)\n",
      "video 1/1 (1001/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.033s), strongsort:(0.033s)\n",
      "video 1/1 (1006/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.034s)\n",
      "No detections\n",
      "No detections\n",
      "video 1/1 (1021/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.034s)\n",
      "video 1/1 (1026/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.035s)\n",
      "No detections\n",
      "No detections\n",
      "video 1/1 (1041/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.037s), strongsort:(0.036s)\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "video 1/1 (1061/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.036s), strongsort:(0.035s)\n",
      "No detections\n",
      "video 1/1 (1071/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.037s), strongsort:(0.031s)\n",
      "No detections\n",
      "video 1/1 (1081/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.037s), strongsort:(0.029s)\n",
      "video 1/1 (1086/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.036s), strongsort:(0.029s)\n",
      "video 1/1 (1091/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.031s)\n",
      "video 1/1 (1096/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.036s), strongsort:(0.028s)\n",
      "video 1/1 (1101/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.036s), strongsort:(0.027s)\n",
      "video 1/1 (1106/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.038s), strongsort:(0.026s)\n",
      "video 1/1 (1111/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.036s), strongsort:(0.026s)\n",
      "video 1/1 (1116/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.034s), strongsort:(0.024s)\n",
      "video 1/1 (1121/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.040s), strongsort:(0.024s)\n",
      "video 1/1 (1126/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.038s), strongsort:(0.024s)\n",
      "video 1/1 (1131/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.041s), strongsort:(0.029s)\n",
      "video 1/1 (1136/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.043s), strongsort:(0.025s)\n",
      "video 1/1 (1141/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.063s), strongsort:(0.031s)\n",
      "video 1/1 (1146/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.055s), strongsort:(0.026s)\n",
      "video 1/1 (1151/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.039s), strongsort:(0.025s)\n",
      "video 1/1 (1156/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.036s), strongsort:(0.028s)\n",
      "video 1/1 (1161/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.054s), strongsort:(0.037s)\n",
      "video 1/1 (1166/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.042s), strongsort:(0.023s)\n",
      "video 1/1 (1171/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.041s), strongsort:(0.023s)\n",
      "video 1/1 (1176/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.038s), strongsort:(0.020s)\n",
      "video 1/1 (1181/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.038s), strongsort:(0.021s)\n",
      "video 1/1 (1186/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.045s), strongsort:(0.020s)\n",
      "video 1/1 (1191/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.021s)\n",
      "video 1/1 (1196/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.039s), strongsort:(0.018s)\n",
      "video 1/1 (1201/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.045s), strongsort:(0.017s)\n",
      "No detections\n",
      "video 1/1 (1211/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.047s), strongsort:(0.017s)\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "Speed: 0.6ms pre-process, 39.3ms inference, 0.4ms NMS, 8.4ms strongsort update per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1m/Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/runs/track/exp2\u001b[0m\n",
      "0 tracks saved to /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/runs/track/exp2/tracks\n"
     ]
    }
   ],
   "source": [
    "# Run the track and sort function on the video specified here !!!! ---\n",
    "def track_cars(video_path, threshold_1,threshold_2, smallest_boundingbox_w, smallest_boundingbox_h):\n",
    "    print(os.getcwd())\n",
    "    # set path to video\n",
    "    opt = parse_opt(video_path)\n",
    "    # check_requirements(requirements=ROOT / 'requirements.txt', exclude=('tensorboard', 'thop'))\n",
    "    width = int(cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    run(**vars(opt), threshold_1=int(height*threshold_1), threshold_2=int(height*threshold_2), smallest_boundingbox_width=smallest_boundingbox_w, smallest_boundingbox_heigth=smallest_boundingbox_h)\n",
    "    return width, height\n",
    "\n",
    "# enter threshold values here`\n",
    "frame_width, frame_height = track_cars(video_path='IMG_0346.mp4', threshold_1=0.98, threshold_2=0.75, smallest_boundingbox_w=150, smallest_boundingbox_h=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it\n"
     ]
    }
   ],
   "source": [
    "frame_width = int(cv2.VideoCapture('./IMG_0346.mp4').get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cv2.VideoCapture('./IMG_0346.mp4').get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(os.getcwd())\n",
    "file_pth = \"exp2\"\n",
    "number_of_cars_in_file = 3\n",
    "\n",
    "def load_data():\n",
    "    data_file = glob.glob('runs/track/'+file_pth+'/tracks/*.csv')\n",
    "    with open(data_file[0], 'r') as f:\n",
    "        data = list(csv.reader(f))\n",
    "        f.close()\n",
    "        return  [[float(x) for x in row] for row in data]\n",
    "\n",
    "\n",
    "def delete_data(all_ids):\n",
    "    data_file = glob.glob('runs/track/'+file_pth+'/tracks/*.csv')\n",
    "    keep_rows = list()\n",
    "    with open(data_file[0], 'r') as f:\n",
    "        data = list(csv.reader(f))\n",
    "        for row in data:\n",
    "            if int(float(row[1])) not in all_ids:\n",
    "                keep_rows.append(row)\n",
    "\n",
    "    # write the rows we want to keep to the file\n",
    "    with open(data_file[0], 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(keep_rows)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def sort_into_dict(data):\n",
    "    dict = {}\n",
    "    for each_entry in data:\n",
    "        frame_number = int(each_entry[0])\n",
    "        car_id = int(each_entry[1])\n",
    "        bounding_box_and_time = [each_entry[2:6], each_entry[6]]\n",
    "\n",
    "        # check if id already exists in dict then append the data to the list with the frame number as key\n",
    "        if car_id in dict:\n",
    "            dict[car_id][frame_number] = bounding_box_and_time\n",
    "        else:\n",
    "            dict[car_id] = {frame_number: bounding_box_and_time}\n",
    "\n",
    "\n",
    "    # remove the ids that have less than 5 entries because:\n",
    "    # they might be cars that are on their way in our out of the frame or just noise\n",
    "    ids_to_remove = []\n",
    "    for each_id in dict: \n",
    "        if len(dict[each_id]) < number_of_cars_in_file:\n",
    "            ids_to_remove.append(each_id)\n",
    "\n",
    "    for each_id in ids_to_remove:\n",
    "        del dict[each_id]\n",
    "\n",
    "    return dict\n",
    "\n",
    "\n",
    "def get_best_license_plate(car_dict):\n",
    "    car_entering = False\n",
    "    sorting_list = []\n",
    "    \n",
    "    for frame_number in car_dict:\n",
    "        # frame = each[0]\n",
    "        size = car_dict[frame_number][0][-1] * car_dict[frame_number][0][-2]\n",
    "        right_side = car_dict[frame_number][0][0] + car_dict[frame_number][0][2]\n",
    "        left_side = car_dict[frame_number][0][0]\n",
    "        \n",
    "        if (left_side > 5) and (right_side < (frame_width-5)):\n",
    "            sorting_list.append((frame_number, size))\n",
    "\n",
    "    # sort the list by bounding box size\n",
    "    sorting_list.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # check if the biggest frame is the first or last frame, which means the car is entering or leaving the frame\n",
    "    length_of_sort = len(sorting_list)-1\n",
    "    if sorting_list[0][0] > sorting_list[length_of_sort][0] and sorting_list[0][0] > sorting_list[int(length_of_sort/2)][0]:\n",
    "        car_entering = True\n",
    "\n",
    "    # return boolean if car is entering or leaving the parking lot, and the frame numbers of the 3 biggest bounding boxes found\n",
    "    return car_entering, [x[0] for x in sorting_list[:3]]\n",
    "\n",
    "\n",
    "def load_image(frame_number, bounding_box_array):\n",
    "    # load image\n",
    "    img = cv2.imread('runs/track/'+file_pth+'/frame id_'+str(frame_number)+'.jpg')\n",
    "    # crop the image to the size of the bounding box\n",
    "    img = img[int(bounding_box_array[1]):int(bounding_box_array[1]+bounding_box_array[3]), int(bounding_box_array[0]):int(bounding_box_array[0]+bounding_box_array[2])]\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_car_images(car_dict):\n",
    "    car_array = []\n",
    "    for car_id in car_dict:\n",
    "        # get the best license plate for each car\n",
    "        car_entering, frames = get_best_license_plate(car_dict[car_id])\n",
    "        cropped_car_images = []\n",
    "        for each_frame in frames:\n",
    "            img = load_image(each_frame, car_dict[car_id][each_frame][0])\n",
    "            cropped_car_images.append(img)\n",
    "        \n",
    "        car_array.append([car_entering, cropped_car_images])\n",
    "\n",
    "    return car_array\n",
    "\n",
    "\n",
    "def delete_images(car_dictionary):\n",
    "    # frames with multiple cars\n",
    "    # frames with no cars\n",
    "    # \n",
    "\n",
    "    for car_id in car_dictionary:\n",
    "        for frame in car_dictionary[car_id]:\n",
    "            os.remove('runs/track/'+file_pth+'/frame id_'+str(frame)+'.jpg')\n",
    "\n",
    "\n",
    "# TODO: if frame contains multiple cars, do not delete the image\n",
    "\n",
    "def fetch_cars():\n",
    "    # load data from csv file\n",
    "    data = load_data()\n",
    "\n",
    "    # sort data into dictionary\n",
    "    car_dictionary = sort_into_dict(data)\n",
    "\n",
    "    # delete the loaded data from the csv file\n",
    "    delete_data(list(car_dictionary.keys()))\n",
    "\n",
    "    # get the 3 best license plate photos for each car and the direction of the car\n",
    "    car_array = get_car_images(car_dictionary)\n",
    "    \n",
    "    # delete the images containing the cars extracted\n",
    "    delete_images(car_dictionary)\n",
    "\n",
    "    return car_array\n",
    "    \n",
    "\n",
    "cars_for_peshang = fetch_cars()\n",
    "\n",
    "image = cars_for_peshang[0][1][0]\n",
    "cv2.imshow('image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('park-3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c78971681c6377feb4c3618006d2345508a16adb1ec61e460d27689553b2b85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
