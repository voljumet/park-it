{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Park a lot\n",
    "\n",
    "This notebook is put together by the following parts:  \n",
    "1. A function to segment video frames to locate cars, which will be used to check if the car is going in or out of the parking lot or garage.  \n",
    "2. A function to read license plate on the segmented frames that will be converted to a string and stored in the \n",
    "3. A csv file containing the parking times of the license plates and the size of the car.\n",
    "4. An additional csv file containing the cars currently in the parking that will be checked against when a license plate apears on the camera.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "# to run the code, the following are required, and should be installed in a new environment:\n",
    "\n",
    "# create new environment\n",
    "%conda create -n \"park-3.9\" python=3.9 ipython\n",
    "# activate environment\n",
    "%conda activate park-3.9\n",
    "# install package\n",
    "%conda install numpy\n",
    "# install requirements.txt\n",
    "%pip install -r requirements.txt --verbose\n",
    "# install ipykernel\n",
    "%conda install -n park-3.9 ipykernel --update-deps --force-reinstall\n",
    "# install libraries that reads text from images\n",
    "%pip install easyocr==1.6.2\n",
    "%conda install pytesseract=0.3.10 -y\n",
    "\n",
    "# Code that detects license plates:\n",
    "# https://github.com/deepakat002/numberplaterecognition\n",
    "\n",
    "\n",
    "# Model to read text from images: (best_submission.pt)\n",
    "\n",
    "# TODO: add corect link to model\n",
    "# https://github.com/pracool/ANPR-with-YoloV5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/park-3.9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# limit the number of cpus used by high performance libraries\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"4\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"4\"\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import csv\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it\n"
     ]
    }
   ],
   "source": [
    "# import more libraries ++\n",
    "ROOT = Path(os.getcwd()).resolve()  # yolov5 strongsort root directory\n",
    "WEIGHTS = ROOT / 'weights'\n",
    "print(os.getcwd())\n",
    "\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "if str(ROOT / 'yolov5') not in sys.path:\n",
    "    sys.path.append(str(ROOT / 'yolov5'))  # add yolov5 ROOT to PATH\n",
    "if str(ROOT / 'trackers' / 'strong_sort') not in sys.path:\n",
    "    sys.path.append(str(ROOT / 'trackers' / 'strong_sort'))  # add strong_sort ROOT to PATH\n",
    "if str(ROOT / 'trackers' / 'strong_sort' / 'sort') not in sys.path:\n",
    "    sys.path.append(str(ROOT / 'trackers' / 'strong_sort' / 'sort'))  # add strong_sort ROOT to PATH\n",
    "\n",
    "import logging\n",
    "from yolov5.models.common import DetectMultiBackend\n",
    "from yolov5.utils.dataloaders import VID_FORMATS, LoadImages, LoadStreams\n",
    "from yolov5.utils.general import (LOGGER, check_img_size, non_max_suppression, scale_boxes, check_requirements, cv2,\n",
    "                                  check_imshow, xyxy2xywh, increment_path, strip_optimizer, colorstr, print_args, check_file)\n",
    "from yolov5.utils.torch_utils import select_device, time_sync\n",
    "from yolov5.utils.plots import Annotator, colors, save_one_box\n",
    "from trackers.multi_tracker_zoo import create_tracker\n",
    "\n",
    "# set working directory to this file\n",
    "os.chdir(ROOT)\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track and sort\n",
    "@torch.no_grad()\n",
    "def run(threshold_1=1,\n",
    "        threshold_2=1,\n",
    "        smallest_boundingbox_width=1,\n",
    "        smallest_boundingbox_heigth=1,\n",
    "        source='0',\n",
    "        yolo_weights=WEIGHTS / 'yolov5m.pt',  # model.pt path(s),\n",
    "        reid_weights=WEIGHTS / 'osnet_x0_25_msmt17.pt',  # model.pt path,\n",
    "        tracking_method='strongsort',\n",
    "        imgsz=(640, 640),  # inference size (height, width)\n",
    "        conf_thres=0.25,  # confidence threshold\n",
    "        iou_thres=0.45,  # NMS IOU threshold\n",
    "        max_det=1000,  # maximum detections per image\n",
    "        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "        show_vid=False,  # show results\n",
    "        save_txt=False,  # save results to *.txt\n",
    "        save_conf=False,  # save confidences in --save-txt labels\n",
    "        save_crop=False,  # save cropped prediction boxes\n",
    "        save_vid=False,  # save confidences in --save-txt labels\n",
    "        nosave=False,  # do not save images/videos\n",
    "        classes=None,  # filter by class: --class 0, or --class 0 2 3\n",
    "        agnostic_nms=False,  # class-agnostic NMS\n",
    "        augment=False,  # augmented inference\n",
    "        visualize=False,  # visualize features\n",
    "        update=False,  # update all models\n",
    "        project=ROOT / 'runs/track',  # save results to project/name\n",
    "        name='exp',  # save results to project/name\n",
    "        exist_ok=False,  # existing project/name ok, do not increment\n",
    "        line_thickness=2,  # bounding box thickness (pixels)\n",
    "        hide_labels=False,  # hide labels\n",
    "        hide_conf=False,  # hide confidences\n",
    "        hide_class=False,  # hide IDs\n",
    "        half=False,  # use FP16 half-precision inference\n",
    "        dnn=False,  # use OpenCV DNN for ONNX inference\n",
    "        vid_stride=1,  # video frame-rate stride\n",
    "):\n",
    "\n",
    "    source = str(source)\n",
    "    save_img = not nosave and not source.endswith('.txt')  # save inference images\n",
    "    is_file = Path(source).suffix[1:] in (VID_FORMATS)\n",
    "    is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
    "    webcam = source.isnumeric() or source.endswith('.txt') or (is_url and not is_file)\n",
    "    if is_url and is_file:\n",
    "        source = check_file(source)  # download\n",
    "\n",
    "    # Directories\n",
    "    if not isinstance(yolo_weights, list):  # single yolo model\n",
    "        exp_name = yolo_weights.stem\n",
    "    elif type(yolo_weights) is list and len(yolo_weights) == 1:  # single models after --yolo_weights\n",
    "        exp_name = Path(yolo_weights[0]).stem\n",
    "    else:  # multiple models after --yolo_weights\n",
    "        exp_name = 'ensemble'\n",
    "    exp_name = name if name else exp_name + \"_\" + reid_weights.stem\n",
    "    save_dir = increment_path(Path(project) / exp_name, exist_ok=exist_ok)  # increment run\n",
    "    (save_dir / 'tracks' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "    # Load model\n",
    "    device = select_device(device)\n",
    "    model = DetectMultiBackend(yolo_weights, device=device, dnn=dnn, data=None, fp16=half)\n",
    "    stride, names, pt = model.stride, model.names, model.pt\n",
    "    imgsz = check_img_size(imgsz, s=stride)  # check image size\n",
    "\n",
    "    # Dataloader\n",
    "    if webcam:\n",
    "        show_vid = check_imshow()\n",
    "        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)\n",
    "        nr_sources = len(dataset)\n",
    "    else:\n",
    "        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)\n",
    "        nr_sources = 1\n",
    "    vid_path, vid_writer, txt_path = [None] * nr_sources, [None] * nr_sources, [None] * nr_sources\n",
    "\n",
    "    # Create as many strong sort instances as there are video sources\n",
    "    tracker_list = []\n",
    "    for i in range(nr_sources):\n",
    "        tracker = create_tracker(tracking_method, reid_weights, device, half)\n",
    "        tracker_list.append(tracker, )\n",
    "        if hasattr(tracker_list[i], 'model'):\n",
    "            if hasattr(tracker_list[i].model, 'warmup'):\n",
    "                tracker_list[i].model.warmup()\n",
    "    outputs = [None] * nr_sources\n",
    "    print(outputs)\n",
    "\n",
    "    # Run tracking\n",
    "    #model.warmup(imgsz=(1 if pt else nr_sources, 3, *imgsz))  # warmup\n",
    "    dt, seen = [0.0, 0.0, 0.0, 0.0], 0\n",
    "    curr_frames, prev_frames = [None] * nr_sources, [None] * nr_sources\n",
    "    temp_array = \"\"\n",
    "    for frame_idx, (path, im, im0s, vid_cap, s) in enumerate(dataset):\n",
    "        if frame_idx % 5 != 0:\n",
    "            continue\n",
    "        t1 = time_sync()\n",
    "        im = torch.from_numpy(im).to(device)\n",
    "        im = im.half() if half else im.float()  # uint8 to fp16/32\n",
    "        im /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]  # expand for batch dim\n",
    "        t2 = time_sync()\n",
    "        dt[0] += t2 - t1\n",
    "\n",
    "        # Inference\n",
    "        visualize = increment_path(save_dir / Path(path[0]).stem, mkdir=True) if visualize else False\n",
    "        pred = model(im, augment=augment, visualize=visualize)\n",
    "        t3 = time_sync()\n",
    "        dt[1] += t3 - t2\n",
    "\n",
    "        # Apply NMS\n",
    "        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
    "        dt[2] += time_sync() - t3\n",
    "\n",
    "        \n",
    "        # Process detections\n",
    "        for i, det in enumerate(pred):  # detections per image\n",
    "            seen += 1\n",
    "            if webcam:  # nr_sources >= 1\n",
    "                p, im0, _ = path[i], im0s[i].copy(), dataset.count\n",
    "                p = Path(p)  # to Path\n",
    "                s += f'{i}: '\n",
    "                txt_file_name = p.name\n",
    "                save_path = str(save_dir / p.name)  # im.jpg, vid.mp4, ...\n",
    "            else:\n",
    "                p, im0, _ = path, im0s.copy(), getattr(dataset, 'frame', 0)\n",
    "                p = Path(p)  # to Path\n",
    "                # video file\n",
    "                if source.endswith(VID_FORMATS):\n",
    "                    txt_file_name = p.stem\n",
    "                    save_path = str(save_dir / p.name)  # im.jpg, vid.mp4, ...\n",
    "                # folder with imgs\n",
    "                else:\n",
    "                    txt_file_name = p.parent.name  # get folder name containing current img\n",
    "                    save_path = str(save_dir / p.parent.name)  # im.jpg, vid.mp4, ...\n",
    "            curr_frames[i] = im0\n",
    "\n",
    "            txt_path = str(save_dir / 'tracks' / txt_file_name)  # im.txt\n",
    "            s += '%gx%g ' % im.shape[2:]  # print string\n",
    "            imc = im0.copy() if save_crop else im0  # for save_crop\n",
    "\n",
    "            annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "            \n",
    "            if hasattr(tracker_list[i], 'tracker') and hasattr(tracker_list[i].tracker, 'camera_update'):\n",
    "                if prev_frames[i] is not None and curr_frames[i] is not None:  # camera motion compensation\n",
    "                    tracker_list[i].tracker.camera_update(prev_frames[i], curr_frames[i])\n",
    "\n",
    "            if det is not None and len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()  # xyxy\n",
    "\n",
    "                # Print results\n",
    "                for c in det[:, -1].unique():\n",
    "                    n = (det[:, -1] == c).sum()  # detections per class\n",
    "                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "\n",
    "                # pass detections to strongsort\n",
    "                t4 = time_sync()\n",
    "                outputs[i] = tracker_list[i].update(det.cpu(), im0)\n",
    "                t5 = time_sync()\n",
    "                dt[3] += t5 - t4\n",
    "\n",
    "                # draw boxes for visualization\n",
    "                if len(outputs[i]) > 0:\n",
    "                    for j, (output, conf) in enumerate(zip(outputs[i], det[:, 4])):\n",
    "\n",
    "\n",
    "                    # ------------------------------------------------------ SAVE TO FILE  ----------------------------------------------------------\n",
    "                        bbox_top = output[1]\n",
    "                        bbox_w = output[2] - output[0]\n",
    "                        bbox_h = output[3] - output[1]\n",
    "\n",
    "                        cv2.line(im0, (0, threshold_1), (im0.shape[1], threshold_1), (255, 0, 0), 2) # Blue\n",
    "                        cv2.line(im0, (0, threshold_2), (im0.shape[1], threshold_2), (255, 0, 0), 2) # Blue\n",
    "\n",
    "                        if (bbox_top+bbox_h < threshold_1) and (bbox_top+bbox_h > threshold_2) and(bbox_w > smallest_boundingbox_width) and (bbox_h > smallest_boundingbox_heigth):\n",
    "                            cv2.imwrite(str(save_dir)+\"/frame id_\"+str(frame_idx+1)+\".jpg\", im0)\n",
    "\n",
    "\n",
    "                            bboxes = output[0:4]\n",
    "                            id = output[4]\n",
    "                            cls = output[5]\n",
    "                            if save_txt:\n",
    "                                # to MOT format\n",
    "                                bbox_left = output[0]\n",
    "                                # append to string\n",
    "\n",
    "                                # add info to array\n",
    "                                if frame_idx % 100 != 0:\n",
    "                                    temp_array += f'{frame_idx + 1},{id},{bbox_left},{bbox_top},{bbox_w},{bbox_h},{time.time()}\\n'\n",
    "                                else:\n",
    "                                    # Write MOT compliant results to file\n",
    "                                    with open(txt_path + '.csv', 'a') as f:\n",
    "                                        f.write(temp_array)\n",
    "                                        f.close()\n",
    "                                        temp_array = \"\"\n",
    "\n",
    "                            if save_vid or save_crop or show_vid:  # Add bbox to image\n",
    "                                c = int(cls)  # integer class\n",
    "                                id = int(id)  # integer id\n",
    "                                label = None if hide_labels else (f'{id} {names[c]}' if hide_conf else \\\n",
    "                                    (f'{id} {conf:.2f}' if hide_class else f'{id} {names[c]} {conf:.2f}'))\n",
    "                                annotator.box_label(bboxes, label, color=colors(c, True))\n",
    "                                if save_crop:\n",
    "                                    txt_file_name = txt_file_name if (isinstance(path, list) and len(path) > 1) else ''\n",
    "                                    save_one_box(bboxes, imc, file=save_dir / 'crops' / txt_file_name / names[c] / f'{id}' / f'{p.stem}.jpg', BGR=True)\n",
    "\n",
    "                LOGGER.info(f'{s}Done. yolo:({t3 - t2:.3f}s), {tracking_method}:({t5 - t4:.3f}s)')\n",
    "\n",
    "            else:\n",
    "                #strongsort_list[i].increment_ages()\n",
    "                LOGGER.info('No detections')          \n",
    "\n",
    "            # Stream results\n",
    "            im0 = annotator.result()\n",
    "            if show_vid:\n",
    "                cv2.imshow(str(p), im0)\n",
    "                cv2.waitKey(1)  # 1 millisecond\n",
    "\n",
    "            # Save results (image with detections)\n",
    "            if save_vid:\n",
    "                if vid_path[i] != save_path:  # new video\n",
    "                    vid_path[i] = save_path\n",
    "                    if isinstance(vid_writer[i], cv2.VideoWriter):\n",
    "                        vid_writer[i].release()  # release previous video writer\n",
    "                    if vid_cap:  # video\n",
    "                        fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "                        w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                        h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                    else:  # stream\n",
    "                        fps, w, h = 30, im0.shape[1], im0.shape[0]\n",
    "                    save_path = str(Path(save_path).with_suffix('.mp4'))  # force *.mp4 suffix on results videos\n",
    "                    vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "                vid_writer[i].write(im0)\n",
    "\n",
    "            prev_frames[i] = curr_frames[i]\n",
    "\n",
    "    # Print results\n",
    "    t = tuple(x / seen * 1E3 for x in dt)  # speeds per image\n",
    "    LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS, %.1fms {tracking_method} update per image at shape {(1, 3, *imgsz)}' % t)\n",
    "    if save_txt or save_vid:\n",
    "        s = f\"\\n{len(list(save_dir.glob('tracks/*.txt')))} tracks saved to {save_dir / 'tracks'}\" if save_txt else ''\n",
    "        LOGGER.info(f\"Results saved to {colorstr('bold', save_dir)}{s}\")\n",
    "    if update:\n",
    "        strip_optimizer(yolo_weights)  # update model (to fix SourceChangeWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set arguments for the track and sort function\n",
    "def parse_opt(video_path):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--yolo-weights', nargs='+', type=Path, default=WEIGHTS / 'yolov5n.pt', help='model.pt path(s)')\n",
    "    parser.add_argument('--reid-weights', type=Path, default=WEIGHTS / 'osnet_x0_25_msmt17.pt')\n",
    "    parser.add_argument('--tracking-method', type=str, default='strongsort', help='strongsort, ocsort, bytetrack')\n",
    "    parser.add_argument('--source', type=str, default='0', help='file/dir/URL/glob, 0 for webcam')  \n",
    "    parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=[640], help='inference size h,w')\n",
    "    parser.add_argument('--conf-thres', type=float, default=0.5, help='confidence threshold')\n",
    "    parser.add_argument('--iou-thres', type=float, default=0.5, help='NMS IoU threshold')\n",
    "    parser.add_argument('--max-det', type=int, default=1000, help='maximum detections per image')\n",
    "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "    parser.add_argument('--show-vid', action='store_true', help='display tracking video results')\n",
    "    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')\n",
    "    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')\n",
    "    parser.add_argument('--save-crop', action='store_true', help='save cropped prediction boxes')\n",
    "    parser.add_argument('--save-vid', action='store_true', help='save video tracking results')\n",
    "    parser.add_argument('--nosave', action='store_true', help='do not save images/videos')\n",
    "    # class 0 is person, 1 is bycicle, 2 is car... 79 is oven\n",
    "    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --classes 0, or --classes 0 2 3')\n",
    "    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')\n",
    "    parser.add_argument('--augment', action='store_true', help='augmented inference')\n",
    "    parser.add_argument('--visualize', action='store_true', help='visualize features')\n",
    "    parser.add_argument('--update', action='store_true', help='update all models')\n",
    "    parser.add_argument('--project', default=ROOT / 'runs/track', help='save results to project/name')\n",
    "    parser.add_argument('--name', default='exp', help='save results to project/name')\n",
    "    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
    "    parser.add_argument('--line-thickness', default=2, type=int, help='bounding box thickness (pixels)')\n",
    "    parser.add_argument('--hide-labels', default=False, action='store_true', help='hide labels')\n",
    "    parser.add_argument('--hide-conf', default=False, action='store_true', help='hide confidences')\n",
    "    parser.add_argument('--hide-class', default=False, action='store_true', help='hide IDs')\n",
    "    parser.add_argument('--half', action='store_true', help='use FP16 half-precision inference')\n",
    "    parser.add_argument('--dnn', action='store_true', help='use OpenCV DNN for ONNX inference')\n",
    "    parser.add_argument('--vid-stride', type=int, default=1, help='video frame-rate stride')\n",
    "\n",
    "    opt = parser.parse_args(['--source', video_path,\n",
    "                             '--classes', '2',\n",
    "                             '--save-txt'\n",
    "                             ,'--show-vid'\n",
    "                             ])\n",
    "\n",
    "    # source\n",
    "    # opt.source = \"../park-a-lot/film.mp4\"\n",
    "\n",
    "    # detect only car class\n",
    "    # opt.classes = 2\n",
    "    \n",
    "    # save text file\n",
    "    # opt.save_txt = True\n",
    "    # print working directory\n",
    "    # print(os.getcwd())\n",
    "\n",
    "    opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1  # expand\n",
    "    print_args(vars(opt))\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1m2019945111: \u001b[0myolo_weights=/Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/weights/yolov5n.pt, reid_weights=/Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/weights/osnet_x0_25_msmt17.pt, tracking_method=strongsort, source=IMG_0346.mp4, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.5, max_det=1000, device=, show_vid=True, save_txt=True, save_conf=False, save_crop=False, save_vid=False, nosave=False, classes=[2], agnostic_nms=False, augment=False, visualize=False, update=False, project=/Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/runs/track, name=exp, exist_ok=False, line_thickness=2, hide_labels=False, hide_conf=False, hide_class=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 🚀 2022-12-2 Python-3.9.15 torch-1.13.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it\n",
      "Successfully loaded pretrained weights from \"/Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/weights/osnet_x0_25_msmt17.pt\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
      "[None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "video 1/1 (186/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.041s), strongsort:(0.018s)\n",
      "video 1/1 (191/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.033s), strongsort:(0.014s)\n",
      "video 1/1 (196/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.032s), strongsort:(0.015s)\n",
      "video 1/1 (201/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.016s)\n",
      "video 1/1 (206/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.034s), strongsort:(0.016s)\n",
      "video 1/1 (211/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.030s), strongsort:(0.018s)\n",
      "video 1/1 (216/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.040s), strongsort:(0.032s)\n",
      "video 1/1 (221/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.048s), strongsort:(0.023s)\n",
      "video 1/1 (226/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.047s), strongsort:(0.025s)\n",
      "video 1/1 (231/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.043s), strongsort:(0.021s)\n",
      "video 1/1 (236/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.021s)\n",
      "video 1/1 (241/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.037s), strongsort:(0.023s)\n",
      "video 1/1 (246/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.021s)\n",
      "video 1/1 (251/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.043s), strongsort:(0.025s)\n",
      "video 1/1 (256/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.032s), strongsort:(0.021s)\n",
      "video 1/1 (261/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.020s)\n",
      "video 1/1 (266/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.037s), strongsort:(0.022s)\n",
      "video 1/1 (271/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.032s), strongsort:(0.023s)\n",
      "video 1/1 (276/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.042s), strongsort:(0.023s)\n",
      "video 1/1 (281/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.053s), strongsort:(0.021s)\n",
      "video 1/1 (286/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.021s)\n",
      "video 1/1 (291/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.033s), strongsort:(0.021s)\n",
      "video 1/1 (296/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.041s), strongsort:(0.036s)\n",
      "video 1/1 (301/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.036s), strongsort:(0.022s)\n",
      "video 1/1 (306/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.033s), strongsort:(0.024s)\n",
      "video 1/1 (311/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.024s)\n",
      "video 1/1 (316/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.039s), strongsort:(0.032s)\n",
      "video 1/1 (321/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.032s), strongsort:(0.027s)\n",
      "video 1/1 (326/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.033s), strongsort:(0.038s)\n",
      "video 1/1 (331/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.044s)\n",
      "video 1/1 (336/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.033s), strongsort:(0.033s)\n",
      "video 1/1 (341/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.037s), strongsort:(0.036s)\n",
      "video 1/1 (346/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.037s)\n",
      "video 1/1 (351/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.037s)\n",
      "video 1/1 (356/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.050s)\n",
      "video 1/1 (361/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.050s), strongsort:(0.043s)\n",
      "No detections\n",
      "video 1/1 (371/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.033s), strongsort:(0.034s)\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "video 1/1 (401/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.029s)\n",
      "No detections\n",
      "video 1/1 (411/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.033s), strongsort:(0.026s)\n",
      "video 1/1 (416/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.025s)\n",
      "video 1/1 (421/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.030s), strongsort:(0.018s)\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "video 1/1 (986/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.025s)\n",
      "video 1/1 (991/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.028s)\n",
      "video 1/1 (996/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.029s)\n",
      "video 1/1 (1001/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.032s), strongsort:(0.030s)\n",
      "video 1/1 (1006/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.029s), strongsort:(0.031s)\n",
      "No detections\n",
      "No detections\n",
      "video 1/1 (1021/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.033s), strongsort:(0.033s)\n",
      "video 1/1 (1026/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.033s), strongsort:(0.033s)\n",
      "No detections\n",
      "No detections\n",
      "video 1/1 (1041/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.034s)\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "video 1/1 (1061/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.035s)\n",
      "No detections\n",
      "video 1/1 (1071/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.030s)\n",
      "No detections\n",
      "video 1/1 (1081/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.038s), strongsort:(0.030s)\n",
      "video 1/1 (1086/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.027s)\n",
      "video 1/1 (1091/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.032s), strongsort:(0.026s)\n",
      "video 1/1 (1096/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.025s)\n",
      "video 1/1 (1101/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.034s), strongsort:(0.025s)\n",
      "video 1/1 (1106/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.024s)\n",
      "video 1/1 (1111/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.031s)\n",
      "video 1/1 (1116/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.024s)\n",
      "video 1/1 (1121/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.032s), strongsort:(0.032s)\n",
      "video 1/1 (1126/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.034s), strongsort:(0.032s)\n",
      "video 1/1 (1131/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.034s), strongsort:(0.022s)\n",
      "video 1/1 (1136/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.036s)\n",
      "video 1/1 (1141/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.039s), strongsort:(0.024s)\n",
      "video 1/1 (1146/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.032s), strongsort:(0.022s)\n",
      "video 1/1 (1151/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.032s), strongsort:(0.022s)\n",
      "video 1/1 (1156/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.038s), strongsort:(0.024s)\n",
      "video 1/1 (1161/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.036s), strongsort:(0.022s)\n",
      "video 1/1 (1166/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.035s), strongsort:(0.028s)\n",
      "video 1/1 (1171/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.030s), strongsort:(0.020s)\n",
      "video 1/1 (1176/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.018s)\n",
      "video 1/1 (1181/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.032s), strongsort:(0.018s)\n",
      "video 1/1 (1186/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.030s), strongsort:(0.018s)\n",
      "video 1/1 (1191/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.033s), strongsort:(0.021s)\n",
      "video 1/1 (1196/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.030s), strongsort:(0.014s)\n",
      "video 1/1 (1201/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.033s), strongsort:(0.013s)\n",
      "No detections\n",
      "video 1/1 (1211/1233) /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/IMG_0346.mp4: 384x640 1 car, Done. yolo:(0.031s), strongsort:(0.023s)\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "No detections\n",
      "Speed: 0.5ms pre-process, 33.3ms inference, 0.3ms NMS, 8.1ms strongsort update per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1m/Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/runs/track/exp\u001b[0m\n",
      "0 tracks saved to /Users/alex/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/runs/track/exp/tracks\n"
     ]
    }
   ],
   "source": [
    "# Run the track and sort function on the video specified here !!!! ---\n",
    "def track_cars(video_path, threshold_1,threshold_2, smallest_boundingbox_w, smallest_boundingbox_h):\n",
    "    print(os.getcwd())\n",
    "    # set path to video\n",
    "    opt = parse_opt(video_path)\n",
    "    # check_requirements(requirements=ROOT / 'requirements.txt', exclude=('tensorboard', 'thop'))\n",
    "    width = int(cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    run(**vars(opt), threshold_1=int(height*threshold_1), threshold_2=int(height*threshold_2), smallest_boundingbox_width=smallest_boundingbox_w, smallest_boundingbox_heigth=smallest_boundingbox_h)\n",
    "    return width, height\n",
    "\n",
    "# enter threshold values here`\n",
    "frame_width, frame_height = track_cars(video_path='IMG_0346.mp4', threshold_1=0.98, threshold_2=0.75, smallest_boundingbox_w=150, smallest_boundingbox_h=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 2022-12-2 Python-3.9.15 torch-1.13.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 232 layers, 7246518 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EASY_OCR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m array_of_cars_found \u001b[39m=\u001b[39m fetch_cars(number_of_cars_in_file\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, file_pth\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexp\u001b[39m\u001b[39m\"\u001b[39m, frame_width\u001b[39m=\u001b[39mframe_width)\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m each_car \u001b[39min\u001b[39;00m array_of_cars_found:\n\u001b[0;32m----> 7\u001b[0m     detect_and_log_cars(each_car)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/fetching/detect_car_functions.py:141\u001b[0m, in \u001b[0;36mdetect_and_log_cars\u001b[0;34m(car_array)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39m# loop through the three images\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[1;32m    139\u001b[0m     \u001b[39m# print \"working with image number: \", i\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[39m# call the main function\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m     plate_num \u001b[39m=\u001b[39m license_plate_to_text(images[i])\n\u001b[1;32m    142\u001b[0m     \u001b[39m# remve the space in the plate number\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     plate_num \u001b[39m=\u001b[39m plate_num\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/fetching/detect_car_functions.py:113\u001b[0m, in \u001b[0;36mlicense_plate_to_text\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m    109\u001b[0m results \u001b[39m=\u001b[39m detectx(image, model\u001b[39m=\u001b[39mmodel)  \u001b[39m# DETECTION HAPPENING HERE\u001b[39;00m\n\u001b[1;32m    111\u001b[0m frame \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(image, cv2\u001b[39m.\u001b[39mCOLOR_RGB2BGR)\n\u001b[0;32m--> 113\u001b[0m plate_num \u001b[39m=\u001b[39m plot_boxes(results, frame, classes\u001b[39m=\u001b[39;49mclasses)\n\u001b[1;32m    115\u001b[0m \u001b[39mreturn\u001b[39;00m plate_num\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/UiA/ikt452_comp_vis/park-it/fetching/detect_car_functions.py:80\u001b[0m, in \u001b[0;36mplot_boxes\u001b[0;34m(results, frame, classes)\u001b[0m\n\u001b[1;32m     76\u001b[0m x1, y1, x2, y2 \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(row[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39mx_shape), \u001b[39mint\u001b[39m(row[\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39my_shape), \u001b[39mint\u001b[39m(\n\u001b[1;32m     77\u001b[0m     row[\u001b[39m2\u001b[39m]\u001b[39m*\u001b[39mx_shape), \u001b[39mint\u001b[39m(row[\u001b[39m3\u001b[39m]\u001b[39m*\u001b[39my_shape)  \u001b[39m# BBOx coordniates\u001b[39;00m\n\u001b[1;32m     78\u001b[0m coords \u001b[39m=\u001b[39m [x1, y1, x2, y2]\n\u001b[1;32m     79\u001b[0m plate_num \u001b[39m=\u001b[39m recognize_plate_easyocr(\n\u001b[0;32m---> 80\u001b[0m     img\u001b[39m=\u001b[39mframe, coords\u001b[39m=\u001b[39mcoords, reader\u001b[39m=\u001b[39mEASY_OCR, region_threshold\u001b[39m=\u001b[39mOCR_TH)\n\u001b[1;32m     81\u001b[0m \u001b[39mreturn\u001b[39;00m plate_num\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EASY_OCR' is not defined"
     ]
    }
   ],
   "source": [
    "from fetching.fetch_car_functions import *\n",
    "from fetching.detect_car_functions import *\n",
    "\n",
    "array_of_cars_found = fetch_cars(number_of_cars_in_file=3, file_pth=\"exp\", frame_width=frame_width)\n",
    "\n",
    "for each_car in array_of_cars_found:\n",
    "    detect_and_log_cars(each_car)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('park-3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c78971681c6377feb4c3618006d2345508a16adb1ec61e460d27689553b2b85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
